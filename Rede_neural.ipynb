{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rede_neural",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vimigueloli/ICPD/blob/main/Rede_neural.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7S8bxf6RrUU"
      },
      "source": [
        "A seguir será desenvolvida a Logica por trás da IA de analise e em seguida essa logica sera convertida em uma classe para implementação do codigo em qualquer aplicação\n",
        "\n",
        "lembrando que para o funcionamento dessa classe apresentada no final do notebook sempre será necessário ajustar a licença para download de arquivos do kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QnwBBJ-ieyO"
      },
      "source": [
        " ##configurando o funcionamento do kaggle para a importação dos dados\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR']='/content'\n",
        "!kaggle datasets download -d fedesoriano/stroke-prediction-dataset ##vale a pena ressaltar que para o funcionamento desse bloco é necessário upar para a aba de arquivos uma licensa de download do site kaggle\n",
        "\n",
        "##Extraindo os arquivos que vieram compactados do kaggle\n",
        "import zipfile\n",
        "with zipfile.ZipFile('/content/stroke-prediction-dataset.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPQweZfWjYoj"
      },
      "source": [
        "##passando os dados que vão ser analizados para uma variavel\n",
        "import pandas as pd\n",
        "dados= pd.read_csv('healthcare-dataset-stroke-data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-Cb-ghqXGNE"
      },
      "source": [
        "##pre processamento dos dados transformando palavras em numeros e preenchendo valores vazios para indicar uma classificação pois IA não lida bem com strings\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "##preenchendo valores vazios\n",
        "dados['smoking_status'] = dados['smoking_status'].replace(['Unknown'], 'never smoked')\n",
        "dados[['bmi']]=dados[['bmi']].fillna(26)\n",
        "\n",
        "##transformando strings em numeros\n",
        "classificador = LabelEncoder() \n",
        "dados[['gender']] = classificador.fit_transform(dados[['gender']])\n",
        "dados[['ever_married']] = classificador.fit_transform(dados[['ever_married']])\n",
        "dados[['work_type']] = classificador.fit_transform(dados[['work_type']])\n",
        "dados[['Residence_type']] = classificador.fit_transform(dados[['Residence_type']])\n",
        "dados[['smoking_status']] = classificador.fit_transform(dados[['smoking_status']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UB8d_zJCdf9"
      },
      "source": [
        "## gerando graficos de comparação de dados do banco\n",
        "import seaborn as snb\n",
        "\n",
        "snb.pairplot(dados,hue = 'stroke')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oSR2YjvSwN4"
      },
      "source": [
        "vale apena destacar que os proximos 3 blocos de código são escolhas diferentes de trabalhar com o banco de dado e foi decidido expor as 3 opções para mostrar o estudo feito na escolha da melhor forma de lidar com os dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfWN29WG8-vV"
      },
      "source": [
        "##aleatoriza os dados para demonstrar a rede neural no caso de que o undersampling ou o oversampling não sejam feitos\n",
        "import sklearn.utils\n",
        "\n",
        "sklearn.utils.shuffle(dados)\n",
        "x= dados[['gender','age','hypertension','heart_disease','ever_married','work_type','Residence_type','avg_glucose_level','bmi','smoking_status']]\n",
        "y= dados[['stroke']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J8k5eiEE-aN"
      },
      "source": [
        "##faz o undersampling\n",
        "import numpy as np\n",
        "\n",
        "## separa os pacientes que não tiveram derrame\n",
        "saudaveis = dados[dados.stroke == 0].index\n",
        "\n",
        "amostra_s = np.random.choice(saudaveis, 250, replace=False)\n",
        "## separa os pacientes que tiveram derrame\n",
        "doentes = dados[dados.stroke == 1].index\n",
        "\n",
        "##junta os pacientes e sapara os dados a serem analizados das conclusões laboratoriais\n",
        "amostra = dados.loc[amostra_s]\n",
        "amostra = amostra.append(dados.loc[doentes])\n",
        "dados = amostra\n",
        "x= dados[['gender','age','hypertension','heart_disease','ever_married','work_type','Residence_type','avg_glucose_level','bmi','smoking_status']]\n",
        "y= dados[['stroke']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GxJ_03rb4Xo"
      },
      "source": [
        "##faz o Oversampling para lidar com o banco de dados desbalanceado\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "\n",
        "##separa os dados a serem analizados das conclusões laboratoriais\n",
        "x= dados[['gender','age','hypertension','heart_disease','ever_married','work_type','Residence_type','avg_glucose_level','bmi','smoking_status']]\n",
        "y= dados[['stroke']]\n",
        "\n",
        "##gera os dados de maneira estatistica\n",
        "smt=SMOTENC(categorical_features=[0, 2], random_state=0)\n",
        "x,y = smt.fit_resample(x,y)\n",
        "\n",
        "## arredonda e reagrupa os dados em uma dataframe pandas \n",
        "x = pd.DataFrame(x,columns=['gender','age','hypertension','heart_disease','ever_married','work_type','Residence_type','avg_glucose_level','bmi','smoking_status'])\n",
        "x['work_type'] = x['work_type'].round(0)      \n",
        "x['smoking_status'] = x['smoking_status'].round(0)  \n",
        "x['Residence_type'] = x['Residence_type'].round(0)\n",
        "x['heart_disease'] = x['heart_disease'].round(0)\n",
        "x['ever_married'] = x['ever_married'].round(0)\n",
        "x['age'] = x['age'].round(0)\n",
        "y = pd.DataFrame(y,columns=['stroke'])\n",
        "\n",
        "## reconstroi o dataframe original após o oversampling para analises\n",
        "dados = x\n",
        "dados.insert(10, 'stroke', 0, allow_duplicates=False)\n",
        "dados[['stroke']] = y\n",
        "\n",
        "## devido a um bug na reconstrução dos dados o x é novamente separado \n",
        "x = x[['gender','age','hypertension','heart_disease','ever_married','work_type','Residence_type','avg_glucose_level','bmi','smoking_status']]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6siYjV6kcpdG"
      },
      "source": [
        "##mostra os dados após o oversampling  ou under sampling\n",
        "import seaborn as snb\n",
        "\n",
        "snb.pairplot(dados,hue = 'stroke')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzY2ien8ypVm"
      },
      "source": [
        "## rede neural para classificação com porcentagem\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "## separa a amostra de teste e de treino e logo em seguida treina a rede neural\n",
        "treino_x, teste_x, treino_y, teste_y = train_test_split(x,y)\n",
        "modelo = SVC(probability = True, kernel= 'poly',degree=2)\n",
        "modelo.fit(treino_x,treino_y)\n",
        "\n",
        "## apos o treino testa a rede e gera alguns dados para a analise de seu desempenho e para geração de graficos\n",
        "respostas_proba = (modelo.predict_proba(teste_x))*100\n",
        "respostas = modelo.predict(teste_x)\n",
        "acuracia = accuracy_score(teste_y,respostas)\n",
        "acuracia = acuracia*100\n",
        "respostas_proba =pd.DataFrame(respostas_proba,columns=['falha','sucesso']) \n",
        "respostas_proba = respostas_proba[['sucesso']]\n",
        "respostas_certas = teste_y*100\n",
        "print(classification_report(teste_y,respostas))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzaEUgJiErBI"
      },
      "source": [
        "## gerando um grafico para vizualização do desempenho da rede neural\n",
        "import matplotlib.pyplot as mp\n",
        "import numpy as np\n",
        "\n",
        "## define o tamanho da amostra que vai para o grafico\n",
        "respostas_certas = respostas_certas.head(51)\n",
        "respostas_proba = respostas_proba.head(51)\n",
        "\n",
        "## define os dados do grafico e transforma em numpy arrays para que possam ser plotados\n",
        "altura1 = []\n",
        "altura2 = []\n",
        "altura3 = []\n",
        "for eixo in respostas_certas['stroke']:\n",
        "  altura1.append(eixo)\n",
        "for eixo in respostas_proba['sucesso']:\n",
        "  altura2.append(eixo)\n",
        "for altura in altura1:\n",
        "  altura3.append((altura-100)*-1)\n",
        "tamanho = np.arange(51)\n",
        "\n",
        "##plota os dados no grafico\n",
        "fig,ax = mp.subplots(figsize=(20,12))\n",
        "mp.bar(tamanho,altura3,color = '#92e698')\n",
        "mp.bar(tamanho,altura1,color = '#e69292')\n",
        "mp.plot(tamanho,respostas_proba[['sucesso']],lw=1,marker='o',ms=6,c='#4946c5')\n",
        "mp.xlabel('Pacientes')\n",
        "mp.ylabel('porcentagem')\n",
        "mp.grid()\n",
        "mp.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoZXY8CTZAs8"
      },
      "source": [
        "##testa o paciente com a rede gerada\n",
        "\n",
        "##recebe os dados do paciente\n",
        "paciente = [[1,21,0,0,0,1,1,80,26.7,2]]\n",
        "paciente = pd.DataFrame(paciente,columns=['gender','age','hypertension','heart_disease','ever_married','work_type','Residence_type','avg_glucose_level','bmi','smoking_status'])\n",
        "\n",
        "##analiza os dados com a rede neural e mostra o resultado\n",
        "chute = modelo.predict_proba(paciente) * 100\n",
        "chute = pd.DataFrame(chute,columns=['falha','sucesso']) \n",
        "chute[['sucesso']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xnb7AtQ5Bdzb"
      },
      "source": [
        "Transformando esse cogigo em uma classe para que possa ser implementado em uma aplicação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrvu87Q-Bcy8"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as mp\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.svm import SVC\n",
        "\n",
        "class ICPD:\n",
        "\n",
        "  ##declaração da classe\n",
        "  def __init__(self,amostra=True,kernel=1):\n",
        "    self.amostra = amostra\n",
        "    self.kernel = kernel\n",
        "    self.banco\n",
        "    self.X\n",
        "    self.Y\n",
        "    if kernel==1:\n",
        "      self.modelo = SVC(probability = True, kernel= 'rbf',degree=2)\n",
        "    elif kernel==2:\n",
        "      self.modelo = SVC(probability = True, kernel= 'linear',degree=2)\n",
        "    elif kernel==3:\n",
        "      self.modelo = SVC(probability = True, kernel= 'sigmoid',degree=2)\n",
        "    elif kernel==4:\n",
        "      self.modelo = SVC(probability = True, kernel= 'poly',degree=2) \n",
        "    self.certas       \n",
        "    self.proba\n",
        "\n",
        "  ##metodo que passa o banco de dados para uma variavel pandas e pre processa eles\n",
        "  def iniciar(self):\n",
        "    os.environ['KAGGLE_CONFIG_DIR']='/content'\n",
        "    !kaggle datasets download -d fedesoriano/stroke-prediction-dataset\n",
        "    with zipfile.ZipFile('/content/stroke-prediction-dataset.zip', 'r') as zip_ref:\n",
        "      zip_ref.extractall('/content')\n",
        "    dados= pd.read_csv('healthcare-dataset-stroke-data.csv')\n",
        "    dados['smoking_status'] = dados['smoking_status'].replace(['Unknown'], 'never smoked')\n",
        "    dados[['bmi']]=dados[['bmi']].fillna(26)\n",
        "    classificador = LabelEncoder() \n",
        "    dados[['gender']] = classificador.fit_transform(dados[['gender']])\n",
        "    dados[['ever_married']] = classificador.fit_transform(dados[['ever_married']])\n",
        "    dados[['work_type']] = classificador.fit_transform(dados[['work_type']])\n",
        "    dados[['Residence_type']] = classificador.fit_transform(dados[['Residence_type']])\n",
        "    dados[['smoking_status']] = classificador.fit_transform(dados[['smoking_status']])\n",
        "    self.banco = dados\n",
        "\n",
        "  ##metodo que faz o ajuste da amostra via overampling caso 'amostra' == FALSE ou undersampling caso 'amostra' == TRUE  \n",
        "  def ajuste(self):\n",
        "    dados = self.banco\n",
        "    if self.amostra == True:\n",
        "      saudaveis = dados[dados.stroke == 0].index\n",
        "      amostra_s = np.random.choice(saudaveis, 250, replace=False)\n",
        "      doentes = dados[dados.stroke == 1].index\n",
        "      amostra = dados.loc[amostra_s]\n",
        "      amostra = amostra.append(dados.loc[doentes])\n",
        "      dados = amostra\n",
        "      x= dados[['gender','age','hypertension','heart_disease','ever_married','work_type','Residence_type','avg_glucose_level','bmi','smoking_status']]\n",
        "      y= dados[['stroke']]\n",
        "    else:\n",
        "      x= dados[['gender','age','hypertension','heart_disease','ever_married','work_type','Residence_type','avg_glucose_level','bmi','smoking_status']]\n",
        "      y= dados[['stroke']]\n",
        "      smt=SMOTENC(categorical_features=[0, 2], random_state=0)\n",
        "      x,y = smt.fit_resample(x,y)\n",
        "      x = pd.DataFrame(x,columns=['gender','age','hypertension','heart_disease','ever_married','work_type','Residence_type','avg_glucose_level','bmi','smoking_status'])\n",
        "      x['work_type'] = x['work_type'].round(0)      \n",
        "      x['smoking_status'] = x['smoking_status'].round(0)  \n",
        "      x['Residence_type'] = x['Residence_type'].round(0)\n",
        "      x['heart_disease'] = x['heart_disease'].round(0)\n",
        "      x['ever_married'] = x['ever_married'].round(0)\n",
        "      x['age'] = x['age'].round(0)\n",
        "      y = pd.DataFrame(y,columns=['stroke'])\n",
        "      dados = x\n",
        "      dados.insert(10, 'stroke', 0, allow_duplicates=False)\n",
        "      dados[['stroke']] = y\n",
        "      x = x[['gender','age','hypertension','heart_disease','ever_married','work_type','Residence_type','avg_glucose_level','bmi','smoking_status']]\n",
        "    self.banco= dados\n",
        "    self.X= x\n",
        "    self.Y= y \n",
        "\n",
        "  ##metodo que treina a IA e armazena dados para a geração do grafico\n",
        "  def treino(self):\n",
        "    x= self.X\n",
        "    y= self.Y \n",
        "    treino_x, teste_x, treino_y, teste_y = train_test_split(x,y)\n",
        "    self.modelo.fit(treino_x,treino_y)\n",
        "    respostas_proba = (self.modelo.predict_proba(teste_x))*100\n",
        "    respostas = modelo.predict(teste_x)\n",
        "    respostas_proba =pd.DataFrame(respostas_proba,columns=['falha','sucesso']) \n",
        "    respostas_proba = respostas_proba[['sucesso']]\n",
        "    respostas_certas = teste_y*100\n",
        "    self.certas= respostas_certas\n",
        "    self.proba = respostas_proba\n",
        "\n",
        "  ##metodo que gera um grafico para exibição\n",
        "  def grafico(self):\n",
        "    respostas_certas = self.certas.head(51)\n",
        "    respostas_proba = self.proba.head(51)\n",
        "    altura1 = []\n",
        "    altura2 = []\n",
        "    altura3 = []\n",
        "    for eixo in respostas_certas['stroke']:\n",
        "      altura1.append(eixo)\n",
        "    for eixo in respostas_proba['sucesso']:\n",
        "      altura2.append(eixo)\n",
        "    for altura in altura1:\n",
        "      altura3.append((altura-100)*-1)\n",
        "    tamanho = np.arange(51)\n",
        "    fig,ax = mp.subplots(figsize=(20,12))\n",
        "    mp.bar(tamanho,altura3,color = '#92e698')\n",
        "    mp.bar(tamanho,altura1,color = '#e69292')\n",
        "    mp.plot(tamanho,respostas_proba[['sucesso']],lw=1,marker='o',ms=6,c='#4946c5')\n",
        "    mp.xlabel('Pacientes')\n",
        "    mp.ylabel('porcentagem')\n",
        "    mp.grid()\n",
        "    mp.show()\n",
        "    mp.savefig(\"desempenho.png\",dpi=300)\n",
        "  \n",
        "  ##metodo que recebe os dados do paciente e da um valor em porcentagem da chance dessa pessoa ter derrame de acordo com o banco de dados analizados\n",
        "  def diagnostico(self, genero, age, hypertension, heart_disease, ever_married, work_type, Residence_type, avg_glucose_level, bmi, smoking_status):\n",
        "    paciente = [[genero, age, hypertension, heart_disease, ever_married, work_type, Residence_type, avg_glucose_level, bmi, smoking_status]]\n",
        "    paciente = pd.DataFrame(paciente,columns=['gender','age','hypertension','heart_disease','ever_married','work_type','Residence_type','avg_glucose_level','bmi','smoking_status'])\n",
        "    chute = self.modelo.predict_proba(paciente) * 100\n",
        "    chute = pd.DataFrame(chute,columns=['falha','sucesso']) \n",
        "    return chute[['sucesso']]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}